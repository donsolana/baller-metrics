{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from io import StringIO\n",
    "from nba_api.stats.static import teams\n",
    "from nba_api.stats.static import players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Baller-Metrics\n",
    "\n",
    "### Introduction\n",
    "\n",
    "If you ask me, one of the coolest appilications of Data Science is in sports, asides summary statistics, the field of Sport Analytics deals with the analysis of sport data to reveal insightful patterns that can improve in-game performance, reduce uncertainty in the outcome of games or even uncover overlooked talent. The techniques behind sport analytics are some of the most elegant implementations of mathematical modelling, however, the results are the stuff of headlines.\n",
    "\n",
    "In this project you will journey with me as we curate a robust dataset that will allow for a number of sport analytics techniques. The dataset will be primarily based on game-by-game data for each active player. Information on each team and player attributes will be combined to this dataset to form a database.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scrape Data\n",
    "* Step 2: Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: conclusions and recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Scrape Data\n",
    "\n",
    "In the `baller_metrics_scrapper.py` script, we scrape items from the html table containing the dataset into a dictionary called `Player Stats`. We then convert the dictionary into a dataframe and finally read this dataframe into a csv file.\n",
    "\n",
    "#### Description of Data Sources\n",
    "\n",
    "| Data Set | Format | Description |\n",
    "| ---      | ---    | ---         |\n",
    "|[Game by game data for each player](https://www.basketball-reference.com/players/)| Web pages(html)| The dataset contains  game-by-game data for each active players, freely curated and hosted by ***basketball-reference.com***. Total amount of stats wold make up well over 1 million rows scattered across thousands of pages.|\n",
    "|[Dataset of teams](https://github.com/swar/nba_api)| API | This dataset is from `nba-api` library. The library contains endpoints with updated data and simplied functions for retrieving them|\n",
    "|[Dataset of players](https://github.com/swar/nba_api)| API| From Same end point above, but contains attribute information on tables.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Assess Data\n",
    "\n",
    "Here we have to clean the data. To make the dataset sparkly we folow these steps:\n",
    "1. To add column names\n",
    "2. Remove rows where players did not play, and rows that only contain missing values\n",
    "2. Provide a data dictionary outside this notebook. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "player_stat = pd.read_csv(\"player_stat.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Understanding and cleaning\n",
    "\n",
    "Before reading the dataframe into a database table, we would like to understanding the nature of the data and some of its percularities. In this our case we want to understand why some values are missing and we want to ensure that most of our dataset contains relevant information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# View data types on all tables\n",
    "player_stat.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The scrapper encountered a table differeny from others this table contains LeBron's highschool stats we can entries from this table by filtering for rows without a date i the date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "player_stat = player_stat.iloc[:, 1:]\n",
    "player_stat = player_stat[player_stat.Date.str.match(\"^[0-9]+\")]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "player_stat[\"Date\"] = pd.to_datetime(player_stat[\"Date\"], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "It seems the `GS` also encodes columns where values are missing as  ***Not With Team*** or ***Did Not Dress***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "player_stat[player_stat.FG.isna()].iloc[10:15, 10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "player_stat = player_stat[~((player_stat.GS == \"Did Not Dress\") | (player_stat.GS == \"Not With Team\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "player_stat = player_stat[~((player_stat.MP == \"Did Not Dress\") | (player_stat.MP == \"Not With Team\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Players sometimes get suspended counting the amount of games each player is suspended could be an indicator of each players could be an indicator of a players discliplinary record or play style. For this reason we can create a seperate table for those records and/or add them to the table where we store player attributes.\n",
    "\n",
    "**to do:** create a running total of suspensions in the fact table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "player_suspensions = player_stat[((player_stat.GS == \"Player Suspended\") | (player_stat.MP == \"Player Suspended\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "player_stat = player_stat[~((player_stat.GS == \"Player Suspended\") | (player_stat.MP == \"Player Suspended\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "player_stat.info()#iloc[:, 10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now that we have removed rows where the players didn't play we can now begin to examine the nature of missing in the data. My hunch is that some missing values represent stats that may be zeros.\n",
    "\n",
    "We will investigate using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "player_stat[player_stat.three_pct == 0.0].iloc[10:50, 10:] #Zeros exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "player_stat[player_stat.three_pct.isna()].iloc[10:50, 10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Here we can see that the `three_pct` and `FG_pct` which represent **three point percentage** and **Field goal percentage**. Since zeros exist in the data set this missing values likely mean that the percentage values are **undefined** because the player didn't attempt any shot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "player_stat[player_stat.plus_minus.isna()].iloc[:, 10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "+/- minus scores is a measure how impactful a player has been. Rows where players played less than 1 minute. Seem to be missing. Since these rows carry no information we can exclude them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "player_stat = player_stat[~(player_stat.plus_minus.isna())]\n",
    "player_stat.to_csv('player_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "##### Attribute Tables\n",
    "\n",
    "Here we will source for the attribute columns sourcing data from the `nba-api`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "teams = pd.DataFrame(teams.get_teams())\n",
    "\n",
    "teams = teams.drop('id', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "teams.columns = ['full_name', 'id', 'nickname', 'city', 'state', 'year_founded']\n",
    "teams.to_csv('teams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get all players.\n",
    "players = pd.DataFrame(players.get_players())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "players= players[players.is_active == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#check wheter player names are unique\n",
    "players.full_name.is_unique\n",
    "players = players.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "players.to_csv(\"players.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "### Data Modelling \n",
    "\n",
    "Here we will use a datalake architecture with Amazon S3. With the schema below being defined on read. Data lakes are a secure, cost-effective and flexible approach to storing data. Though they do not inherently enforce constraints like relational databases, they make up for this through high availabity and flexible schemas.\n",
    "\n",
    "\n",
    "1. Fact Table\n",
    "\n",
    "**game_stats** - conatins unaggragated game level statistics\n",
    "\n",
    "***columns -key, game_index, name, Date, Age, home_team_id , away_team_id, Form, GS, MP, FG, FGA, FG_pct,  three, threePA, three_pct, FT, FTA, FT_pct, ORB, DRB, TRB, AST, STL, BLK, TOV, PF, PTS, GmSc, plus_minus***\n",
    "\n",
    "2. Dimensionals Tables\n",
    "\n",
    "**Players** - contains player attributes\n",
    "\n",
    "***full_name, first_name, last_name***\n",
    "\n",
    "\n",
    "**Teams** - contains player attributes\n",
    "\n",
    "***full_name, id, nickname, city, state, year_founded***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Some players exist in the fact table but not the Player table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "players.full_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Reading files to S3 \n",
    "\n",
    "Here we are going to read the files to s3. Using Amazon's SDK `Boto3`. We are goint to use a configuration file and python's `configparser`.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('lake.cfg'))\n",
    "\n",
    "KEY     = config.get('AWS','KEY')\n",
    "SECRET  = config.get('AWS','SECRET')\n",
    "bucket  = config.get('S3','BUCKET')\n",
    "folder  = config.get('S3', 'FOLDER')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "client = boto3.client('s3',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def to_s3(bucket, filename,  folder, subfolder, client):\n",
    "    \"\"\"\n",
    "    uploads files to s3.\n",
    "    - all inputs are strings\n",
    "    \"\"\"\n",
    "    k = folder  + '/' + subfolder + filename\n",
    "    client.upload_file(Filename = filename, Bucket= bucket, Key = k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## upload player_stats\n",
    "to_s3(bucket, \"player_stats.csv\", folder, \"game_stats/\", client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## upload player\n",
    "to_s3(bucket, \"players.csv\", folder, \"players/\", client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## upload player\n",
    "to_s3(bucket, \"teams.csv\", folder, \"teams/\", client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "### Data Quality Checks\n",
    "Here perform two data quality checks\n",
    "1. We check if our files exist in the bucket\n",
    "2. We extract the fact table and confirm rows and columns are present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### check if our files exist in the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def key_existing_size_list(client, bucket, folder, subfolder, filename):\n",
    "    \"\"\"return the key's size if it exist, else None\"\"\"\n",
    "    key = folder  + '/' + subfolder + filename\n",
    "    \n",
    "    response = client.list_objects_v2(\n",
    "        Bucket=bucket,\n",
    "        Prefix=key,\n",
    "    )\n",
    "    for obj in response.get('Contents', []):\n",
    "        if obj['Key'] == key:\n",
    "            return obj['Size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "key_existing_size_list(client, bucket, folder, \"game_stats/\", \"player_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "key_existing_size_list(client, bucket, folder, \"players/\", \"players.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "key_existing_size_list(client, bucket, folder, \"teams/\", \"teams.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### check if rows and columns are present on read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def row_num_s3(client, bucket, folder, subfolder, filename):\n",
    "    key = folder  + '/' + subfolder + filename\n",
    "    csv_obj = client.get_object(Bucket=bucket, Key=key)\n",
    "    body = csv_obj['Body']\n",
    "    csv_string = body.read().decode('utf-8')\n",
    "    df  =pd.read_csv(StringIO(csv_string))\n",
    "    return df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "row_num_s3(client, bucket, folder, 'game_stats/', \"player_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "row_num_s3(client, bucket, folder, 'players/', \"players.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "row_num_s3(client, bucket, folder, 'teams/', \"teams.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data dictionary\n",
    "\n",
    "##### **Player Stats**\n",
    "\n",
    "1. ***key*** -   Unique identifier for each entry. Player name + date \n",
    "2. ***game_index*** - incremental count of games for each player per season\n",
    "3.  ***name*** - Player's full name \n",
    "4.  ***Date*** - Date when game was played\n",
    "5.  ***Age*** - Player's Age\n",
    "6.  ***home_team_id*** - Home team id . Abbrevated name\n",
    "7.  ***away_team_id*** - Away team id. Abbrevated name\n",
    "8.  ***Form*** - Oppenent form\n",
    "9.  ***GS*** - If player started game. Boolean, player started game =1 \n",
    "10. ***MP*** - Minutes played\n",
    "11. ***FG*** - Field goals i.e Non 3 point baskets made from open play\n",
    "12. ***FGA*** - Field Goal Attempts\n",
    "13. ***FG_pct*** - Percentage of field goals made\n",
    "14. ***three*** - Three point\n",
    "15. ***threePA*** - Three point attempts\n",
    "16. ***three_pct*** - Percentage of three points made\n",
    "17. ***FT*** - Free throw\n",
    "18. ***FTA*** - Free throw attempt\n",
    "19. ***FT_pct*** - Free throw percentage\n",
    "20. ***ORB*** - Offensive rebounds\n",
    "21. ***DRB*** - Defensive rebounds\n",
    "22. ***TRB*** - Total rebounds\n",
    "23. ***AST*** - Number of assists in game.\n",
    "24. ***STL*** - Number of Steals made\n",
    "25. ***BLK*** - Block attempts\n",
    "26. ***TOV*** - Number of turnovers\n",
    "27. ***PF***  - Personal Fouls\n",
    "28. ***PTS*** - Total Points\n",
    "29. ***GmSc***- Game Score\n",
    "30. ***plus_minus*** - plus/minus score. A measure of how impactful a player is to his team.\n",
    "\n",
    "#### **teams**\n",
    "1. ***full_name*** - Team full name\n",
    "2. ***id*** - Abbrevated name\n",
    "3. ***nickname*** - Team Nickname \n",
    "4. ***city*** - Team's City\n",
    "5. ***state*** - Team's state\n",
    "6. ***year_founded*** - Founding year\n",
    "\n",
    "#### **players**\n",
    "1. ***full_name*** - Team full name\n",
    "2. ***first_name*** - Team Nickname \n",
    "3. ***last_name*** - Team's City\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Conclusion and Recommendation\n",
    "\n",
    "\n",
    "#### Tools and Technologies\n",
    "1. `AWS S3` for data storage\n",
    "2. AWS Boto3 to access s3 client\n",
    "3. Pandas to manipulate data\n",
    "4. `Apache Spark` supports S3 connections therefore spark can also be used if the dataset is extended. i.e We accomodate retired players.\n",
    "\n",
    "#### Data Update Frequency\n",
    "1. The player_stats table should be played weekly to accomodate for the last matches\n",
    "2. Other tables can be updated annually to accomodate any unlikely changes in values\n",
    "\n",
    "#### Future Designs\n",
    "1. The data was increased by 100x.\n",
    "\t\n",
    "\tPandas may not be able to handle a 100x increase in data can not process 100x data set, we could consider using a spark cluster hosted `Amazon EMR`.\n",
    "\n",
    "2. The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "\n",
    "\t`Apache Airflow` can be used to schedule pipeline. `Airflow` supports service level agreements that can help ensure data is uploadex in time.\n",
    "\n",
    "3. The database needed to be accessed by 100+ people.\n",
    "\n",
    "\tWe can use `Amazon Redshift`. Redshift allows for over 500 connections.\n",
    "    \n",
    "#### To do:\n",
    "1. Automate updates\n",
    "2. Add WNBA and retired players.\n",
    "3. It is very likely that the scrapper will time out before it scrapes all pages for best result we can manually batch the scrapper by adding an index to `url_list`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## References\n",
    "1. [Filter by regex, tutorialspoint.com](https://www.tutorialspoint.com/how-to-filter-rows-in-pandas-by-regex#:~:text=A%20regular%20expression%20%28regex%29%20is%20a%20sequence%20of,regex%2C%20we%20can%20use%20the%20str.match%20%28%29%20method.)\n",
    "\n",
    "2. [Boto to S3](https://stackoverflow.com/questions/48399871/saving-csv-file-to-s3-using-boto3)\n",
    "\n",
    "3. [Check s3 buckets](https://www.peterbe.com/plog/fastest-way-to-find-out-if-a-file-exists-in-s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
